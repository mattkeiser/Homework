{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Matthew Keiser Homework #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1) What is the difference between train and test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A training set is used to develop a model, and a test set is used to assess the predictive capability of the model developed with the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2) Why is it important to have a seperate data set for training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model developed with a set of data can simply memorize the data set for a 100% accurate model. By separating the original data set into a training and testing set, assuming the test set is selected randomly, the actual predictive capability of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3) What are some advantages and disadvantages of the KNN algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN is a simple, quick running algorithm that represents the variability of the entire dataset. It is limited in the number of features that can be used; if there are too many features, all points of data will be approximately equally far from each other, meaning there will be very little variability in the predicted output. Also, the data must be normalized for this algorithm to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4) Explain in your own words the bias variance tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of a less complex model approaches the mean of the data; a less complex model is thus biased toward a single output, and exibits a great deal of error with regard to both the training and testing data sets. A more complex model effectively memorizes the training data set; a more complex model thus results in a large amount of variance, and exibits a great deal of error with regard to the testing data set but little with regard to the training data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##5) Do you think KNN suffers from high bias or high variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When K equals the length of the training dataset, KNN suffers from high bias beacuse it returns the average value of the training dataset, regardless of the input. When K equals one, KNN suffers from high varience because the result is simply the closest point in the training dataset to the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##6) List some possible solutions when suffering from high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance is the result of an over complex model; therefore one remedy is to reduce the complexity - remove features or implement regularization (Ridge or Lasso) when using linear regression; increase K when using KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##7) List some possible solutions when suffereing from high bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias is the result of an under-complex model; therefore, one remedy is to increase complexity in the model - add features (polynomial or interaction) in linear regression; reduce K when using KNN. Another remedy is to add data - additional observations or additional features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##8) Would you choose K when doing K Nearest Neighbors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K is an input for KNN, so a K must be chosen to run the model. However, cross-validation may be used to determine the best (lowest test error) K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Initialize Modules and Red in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn import neighbors\n",
    "from sklearn import metrics\n",
    "from sklearn import grid_search\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import statsmodels.formula.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa  \\\n",
       "0 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0 -0.430783   \n",
       "1 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "2 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20 -0.162519   \n",
       "3 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "4  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0  0.371564   \n",
       "\n",
       "  train  \n",
       "0     T  \n",
       "1     T  \n",
       "2     T  \n",
       "3     T  \n",
       "4     T  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/galvin-mj/DAT_ATL_15/master/Datasets/ProstateCancer.csv')\n",
    "del data['Unnamed: 0']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = data[data['train'] == 'T'].drop('train', 1).drop('lpsa', 1)\n",
    "scaled_train_x = sk.preprocessing.scale(train_x)\n",
    "train_y = data['lpsa'][data['train'] == 'T']\n",
    "scaled_train_y = sk.preprocessing.scale(train_y)\n",
    "test_x = data[data['train'] == 'F'].drop('train', 1).drop('lpsa', 1)\n",
    "scaled_test_x = sk.preprocessing.scale(test_x)\n",
    "test_y = data['lpsa'][data['train'] == 'F']\n",
    "scaled_test_y = sk.preprocessing.scale(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280521</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.675310</td>\n",
       "      <td>0.432417</td>\n",
       "      <td>0.433652</td>\n",
       "      <td>0.734460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.280521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.347969</td>\n",
       "      <td>0.442264</td>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.164537</td>\n",
       "      <td>0.056882</td>\n",
       "      <td>0.107354</td>\n",
       "      <td>0.433319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.347969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.127668</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.276112</td>\n",
       "      <td>0.169593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.442264</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.085843</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.078460</td>\n",
       "      <td>0.179809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>-0.085843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673111</td>\n",
       "      <td>0.320412</td>\n",
       "      <td>0.457648</td>\n",
       "      <td>0.566218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>0.675310</td>\n",
       "      <td>0.164537</td>\n",
       "      <td>0.127668</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>0.673111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514830</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>0.548813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>0.432417</td>\n",
       "      <td>0.056882</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.320412</td>\n",
       "      <td>0.514830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.751905</td>\n",
       "      <td>0.368987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.433652</td>\n",
       "      <td>0.107354</td>\n",
       "      <td>0.276112</td>\n",
       "      <td>0.078460</td>\n",
       "      <td>0.457648</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>0.751905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.422316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lpsa</th>\n",
       "      <td>0.734460</td>\n",
       "      <td>0.433319</td>\n",
       "      <td>0.169593</td>\n",
       "      <td>0.179809</td>\n",
       "      <td>0.566218</td>\n",
       "      <td>0.548813</td>\n",
       "      <td>0.368987</td>\n",
       "      <td>0.422316</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "lcavol   1.000000  0.280521  0.225000  0.027350  0.538845  0.675310  0.432417   \n",
       "lweight  0.280521  1.000000  0.347969  0.442264  0.155385  0.164537  0.056882   \n",
       "age      0.225000  0.347969  1.000000  0.350186  0.117658  0.127668  0.268892   \n",
       "lbph     0.027350  0.442264  0.350186  1.000000 -0.085843 -0.006999  0.077820   \n",
       "svi      0.538845  0.155385  0.117658 -0.085843  1.000000  0.673111  0.320412   \n",
       "lcp      0.675310  0.164537  0.127668 -0.006999  0.673111  1.000000  0.514830   \n",
       "gleason  0.432417  0.056882  0.268892  0.077820  0.320412  0.514830  1.000000   \n",
       "pgg45    0.433652  0.107354  0.276112  0.078460  0.457648  0.631528  0.751905   \n",
       "lpsa     0.734460  0.433319  0.169593  0.179809  0.566218  0.548813  0.368987   \n",
       "\n",
       "            pgg45      lpsa  \n",
       "lcavol   0.433652  0.734460  \n",
       "lweight  0.107354  0.433319  \n",
       "age      0.276112  0.169593  \n",
       "lbph     0.078460  0.179809  \n",
       "svi      0.457648  0.566218  \n",
       "lcp      0.631528  0.548813  \n",
       "gleason  0.751905  0.368987  \n",
       "pgg45    1.000000  0.422316  \n",
       "lpsa     0.422316  1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1) Perform regression on the prostate data set. Your goal is to minimize the mean squared error (MSE). Split this into a several parts and at a minimum utilize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkLearn Linear Regression Mean Squared Error is 0.491127418061\n",
      "SkLearn Linear Regression Intercept is 1.43901040001e-16\n",
      "SkLearn Linear Regression Model Coefficients Are:\n",
      "[(0.59314448426023669, 'lcavol'), (0.24229135512063388, 'lweight'), (-0.11802302729236888, 'age'), (0.17553030474789702, 'lbph'), (0.25634746039416223, 'svi'), (-0.2392803027906078, 'lcp'), (-0.017315211482775372, 'gleason'), (0.22962676117415212, 'pgg45')]\n"
     ]
    }
   ],
   "source": [
    "sk_linreg_model = sk.linear_model.LinearRegression()\n",
    "sk_linreg_model.fit(scaled_train_x,scaled_train_y)\n",
    "linreg_error = metrics.mean_squared_error(scaled_test_y,sk_linreg_model.predict(scaled_test_x))\n",
    "linreg_MSE = ['Linear Regression',linreg_error]\n",
    "\n",
    "print('SkLearn Linear Regression Mean Squared Error is',linreg_error)\n",
    "print('SkLearn Linear Regression Intercept is',sk_linreg_model.intercept_)\n",
    "print('SkLearn Linear Regression Model Coefficients Are:')\n",
    "print([i for i in zip(sk_linreg_model.coef_,train_x.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using Polynomial Features is 1.0910709612\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "poly_linreg_model = sk.linear_model.LinearRegression()\n",
    "poly_linreg_model.fit(poly.fit_transform(scaled_train_x),scaled_train_y)\n",
    "predict = poly_linreg_model.predict(poly.fit_transform(scaled_test_x))\n",
    "poly_linreg_error = metrics.mean_squared_error(scaled_test_y, predict)\n",
    "poly_linreg_MSE = ['Polynomial Linear Regression',poly_linreg_error]\n",
    "\n",
    "print(\"MSE using Polynomial Features is\",poly_linreg_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Mean Squared Error is 0.576583397774\n",
      "Best n_neighbors is 25\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'n_neighbors': [i for i in range(1,50)]}]\n",
    "\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "knn_cv = grid_search.GridSearchCV(knn, param_grid, cv=5)\n",
    "knn_cv.fit(scaled_train_x, scaled_train_y)\n",
    "\n",
    "knn_error = metrics.mean_squared_error(knn_cv.predict(scaled_test_x),scaled_test_y)\n",
    "knn_MSE = ['KNN',knn_error]\n",
    "\n",
    "print('KNN Mean Squared Error is',knn_error)\n",
    "print('Best n_neighbors is',knn_cv.best_params_['n_neighbors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Mean Squared Error is 0.441137837317\n",
      "Best alpha is 0.0612244898898\n",
      "Lasso Regression Model Coefficients Are:\n",
      "[(0.4786536684737166, 'lcavol'), (0.19917885372928815, 'lweight'), (-0.0, 'age'), (0.10850431882662243, 'lbph'), (0.15816887459192672, 'svi'), (-0.0, 'lcp'), (0.0, 'gleason'), (0.067947279716131681, 'pgg45')]\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'alpha': np.linspace(1e-10, 1, 50)}]\n",
    "\n",
    "lasso_rgr = Lasso()\n",
    "lasso_cv = grid_search.GridSearchCV(lasso_rgr, param_grid, cv=10)\n",
    "lasso_cv.fit(scaled_train_x, scaled_train_y)\n",
    "lasso_error = metrics.mean_squared_error(lasso_cv.predict(scaled_test_x),scaled_test_y)\n",
    "lasso_MSE = ['Laso Linear Regression',lasso_error]\n",
    "\n",
    "print('Lasso Mean Squared Error is',lasso_error)\n",
    "print('Best alpha is',lasso_cv.best_params_['alpha'])\n",
    "print('Lasso Regression Model Coefficients Are:')\n",
    "print([i for i in zip(lasso_cv.best_estimator_.coef_,train_x.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso With Polynomial Features Mean Squared Error is 0.39220361882\n",
      "Best alpha is 0.191919192\n",
      "Ridge Regression Model Coefficients Are:\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.          0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.         -0.\n",
      "  0.         -0.         -0.          0.         -0.         -0.          0.\n",
      " -0.         -0.          0.          0.14452591  0.11254657  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      " -0.          0.          0.          0.          0.          0.          0.\n",
      " -0.          0.          0.          0.          0.          0.         -0.\n",
      "  0.          0.         -0.         -0.          0.          0.          0.\n",
      "  0.         -0.          0.          0.          0.02272954  0.          0.\n",
      " -0.         -0.          0.          0.          0.          0.         -0.\n",
      " -0.          0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.         -0.         -0.          0.          0.         -0.\n",
      "  0.         -0.          0.          0.          0.          0.         -0.\n",
      " -0.         -0.          0.          0.         -0.         -0.          0.\n",
      "  0.          0.          0.         -0.          0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.          0.04706686  0.          0.\n",
      "  0.          0.          0.         -0.         -0.          0.          0.\n",
      " -0.          0.         -0.         -0.          0.          0.10119583\n",
      " -0.         -0.          0.         -0.         -0.          0.\n",
      " -0.00626579 -0.          0.         -0.         -0.          0.         -0.\n",
      " -0.          0.         -0.         -0.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'alpha': np.linspace(1e-10, 1, 100)}]\n",
    "mse = metrics.make_scorer(metrics.mean_squared_error, greater_is_better = False)\n",
    "poly = PolynomialFeatures(3)\n",
    "\n",
    "lasso_poly_rgr = sk.linear_model.Lasso(max_iter = 100000)\n",
    "lasso_poly_cv = grid_search.GridSearchCV(lasso_poly_rgr, param_grid, cv=5, scoring=mse)\n",
    "lasso_poly_cv.fit(poly.fit_transform(scaled_train_x), scaled_train_y)\n",
    "Lasso_Poly_MSE = metrics.mean_squared_error(scaled_test_y, lasso_poly_cv.best_estimator_.predict(poly.fit_transform(scaled_test_x)))\n",
    "poly_lasso_MSE = ['Polynomial Lasso Linear Regression',Lasso_Poly_MSE]\n",
    "\n",
    "print('Lasso With Polynomial Features Mean Squared Error is',Lasso_Poly_MSE)\n",
    "print('Best alpha is',lasso_poly_cv.best_params_['alpha'])\n",
    "print('Ridge Regression Model Coefficients Are:')\n",
    "print(lasso_poly_cv.best_estimator_.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Mean Squared Error is 0.485482905513\n",
      "Best alpha is 37.8787878788\n",
      "Ridge Regression Model Coefficients Are:\n",
      "[(0.30495167498017345, 'lcavol'), (0.19078884528850412, 'lweight'), (-0.017343534184502938, 'age'), (0.12444970795079691, 'lbph'), (0.17610914142925241, 'svi'), (0.037911903898169744, 'lcp'), (0.040398113553872669, 'gleason'), (0.098796194966228684, 'pgg45')]\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'alpha': np.linspace(1e-10, 50, 100)}]\n",
    "\n",
    "ridge_rgr = Ridge()\n",
    "ridge_cv = grid_search.GridSearchCV(ridge_rgr, param_grid, cv=10)\n",
    "ridge_cv.fit(scaled_train_x, scaled_train_y)\n",
    "ridge_error = metrics.mean_squared_error(ridge_cv.predict(scaled_test_x),scaled_test_y)\n",
    "ridge_MSE = ['Ridge Linear Regression',ridge_error]\n",
    "    \n",
    "print('Ridge Mean Squared Error is',ridge_error)\n",
    "print('Best alpha is',ridge_cv.best_params_['alpha'])\n",
    "print('Ridge Regression Model Coefficients Are:')\n",
    "print([i for i in zip(ridge_cv.best_estimator_.coef_,train_x.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge With Polynomial Features Mean Squared Error is 0.681824567937\n",
      "Best alpha is 18.3673469388\n",
      "Ridge Regression Model Coefficients Are:\n",
      "[ 0.          0.28795119  0.17441011 -0.03704679  0.13426347  0.11503055\n",
      "  0.02204136  0.08714252  0.09500646 -0.00659429 -0.05369837  0.00312567\n",
      "  0.00255921  0.01421783 -0.1249906  -0.04808827  0.04225505  0.07317194\n",
      "  0.00841089 -0.1492374  -0.06457997 -0.0833132  -0.09013403  0.01223538\n",
      "  0.08611646 -0.0455624  -0.01178977 -0.05418748 -0.05943838  0.01798254\n",
      "  0.01945335 -0.04892894 -0.02166424 -0.0263727   0.06004125  0.15239391\n",
      " -0.04819087 -0.0597749   0.08130842 -0.01375245 -0.03480112  0.05313523\n",
      " -0.01507633 -0.0091455   0.02416796]\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'alpha': np.linspace(1e-10, 50, 50)}]\n",
    "mse = metrics.make_scorer(metrics.mean_squared_error, greater_is_better = False)\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "ridge_poly_rgr = sk.linear_model.Ridge(max_iter = 100000)\n",
    "ridge_poly_cv = grid_search.GridSearchCV(ridge_poly_rgr, param_grid, cv=5, scoring=mse)\n",
    "ridge_poly_cv.fit(poly.fit_transform(scaled_train_x), scaled_train_y)\n",
    "ridge_Poly_MSE = metrics.mean_squared_error(scaled_test_y, ridge_poly_cv.best_estimator_.predict(poly.fit_transform(scaled_test_x)))\n",
    "poly_ridge_MSE = ['Polynomial Ridge Linear Regression',ridge_Poly_MSE]\n",
    "\n",
    "print('Ridge With Polynomial Features Mean Squared Error is',ridge_Poly_MSE)\n",
    "print('Best alpha is',ridge_poly_cv.best_params_['alpha'])\n",
    "print('Ridge Regression Model Coefficients Are:')\n",
    "print(ridge_poly_cv.best_estimator_.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##2) Were there any features that were highly correlated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The strongest correlation was between 'gleason' and 'pgg45'. This suggests they are connected, possibly having similar causes that drive them or measuring a similar parameter in the patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3) What features were the most important? Unimportant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'lcavol' feature generally the largest coefficient, which suggests it has a greatest effect on the value of lpsa. The 'age', 'lcp', 'gleason', and 'pgg45' features all had near zero coefficients (all but 'pgg45' were eliminated by the lasso algorithm), indicating they had little effect on the value of lpsa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4) What model worked best? What was the MSE of each?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model was the lasso method using third degree polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Linear Regression', 0.49112741806094645] ['Polynomial Linear Regression', 1.0910709611975311] ['KNN', 0.57658339777434686] ['Laso Linear Regression', 0.44113783731679246] ['Polynomial Lasso Linear Regression', 0.39220361881957938] ['Ridge Linear Regression', 0.48548290551339857] ['Polynomial Ridge Linear Regression', 0.68182456793670454]\n"
     ]
    }
   ],
   "source": [
    "print(linreg_MSE,poly_linreg_MSE,knn_MSE,lasso_MSE,poly_lasso_MSE,ridge_MSE,poly_ridge_MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##5) What difficulties did you have with this data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There was little variability in the 'gleason' and 'pgg45' features, so they weren't as useful as other features for developing the correlation. Also, when trying to do a lasso linear regression with a second degree polynomial transformation, the model did not converge, though a third degree polynomial transformation did work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
